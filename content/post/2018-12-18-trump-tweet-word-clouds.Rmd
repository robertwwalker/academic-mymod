---
title: Trump Tweet Word Clouds
author: RWW
date: '2018-12-18'
slug: trump-tweet-word-clouds
categories:
  - tidyverse
  - tidytext
tags:
  - tidyverse
  - R Markdown
  - tidytext
header:
  caption: ''
  image: ''
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Mining Twitter Data

Is rather easy.  You have to arrange a developer account with Twitter and set up an app.  After that, Twitter gives you access to a consumer key and secret and an access token and access secret.  Those can be embedded in OAuth to automate searches and the retrieval of data.  My tool of choice for this is *rtweet*  The first section involves setting up a token.


For this one, we need `rtweet` because the tweet text is getting cut.

```{r userFAKE, echo=TRUE, eval=FALSE}
# Change the next four lines based on your own consumer_key, consume_secret, access_token, and access_secret. 
token <- create_token(
  app = "MyAppName",
  consumer_key <- "CK",
  consumer_secret <- "CS",
  access_token <- "AT",
  access_secret <- "AS")
```

Now I want to collect some tweets from a particular user's timeline and look into them.

## Who does Trump tweet about?

A cool post on sentiment analysis can be found [here](http://dataaspirant.com/2018/03/22/twitter-sentiment-analysis-using-r/).  The first step is to grab his timeline.  `rtweet` makes this quite easy.  I will grab it and then save it in the code below so that I do not spam the API.

```{r, eval=FALSE}
tml.djt <- get_timeline("realDonaldTrump", n = 3200)
save(tml.djt, file="../data/TMLS.RData")
```

I start by loading the tmls object that I created above.  What does it look like?

```{r, message=FALSE}
library(tidyverse)
library(tidytext)
load("../../data/TMLS.RData")
names(tml.djt)
```

I want to first get rid of retweets to render President Trump in his own voice.

```{r}
DJTDF <- tml.djt %>% filter(is_retweet==FALSE)
```

With just his tweets, a few things can be easily accomplished.  Who does he mention?

```{r, warning=FALSE}
library(wordcloud)
MNTDJT <- DJTDF %>% filter(!is.na(mentions_screen_name)) %>% select(mentions_screen_name)
Ments <- as.character(unlist(MNTDJT))
wordcloud(Ments)
```

That's interesting.  But that is twitter accounts.  That is far less interesting that his actual text.  

## What does Trump tweet about?

Some more stuff from [stack overflow](https://stackoverflow.com/questions/31348453/how-do-i-clean-twitter-data-in-r).  There is quite a bit of code in here.  I simply wrote a function that takes an input character string and cleans it up.  Uncomment the various components and pipe them.


```{r, warning=FALSE}
library(RColorBrewer)
TDF <- DJTDF %>% select(text)
# TDF contains the text of tweets.
library(stringr)
tweet_cleaner <- function(text) {
  temp1 <- str_replace_all(text, "&amp", "") %>% 
    str_replace_all(., "https://t+", "") %>%
    str_replace_all(.,"@[a-z,A-Z]*","")
#    str_replace_all(., "[[:punct:]]", "")  
#    str_replace_all(., "[[:digit:]]", "") %>%
#    str_replace_all(., "[ \t]{2,}", "") %>%
#    str_replace_all(., "^\\s+|\\s+$", "")  %>%
#    str_replace_all(., " "," ") %>%
#    str_replace_all(., "http://t.co/[a-z,A-Z,0-9]*{8}","")
#    str_replace_all(.,"RT @[a-z,A-Z]*: ","") %>% 
#    str_replace_all(.,"#[a-z,A-Z]*","")
  return(temp1)
}
clean_tweets <- data.frame(text=sapply(1:dim(TDF)[[1]], function(x) {tweet_cleaner(TDF[x,"text"])}))
clean_tweets$text <- as.character(clean_tweets$text)
Trumps.Words <- clean_tweets %>% unnest_tokens(., word, text) %>% anti_join(stop_words, "word")
TTW <- table(Trumps.Words)
TTW <- TTW[order(TTW, decreasing = T)]
TTW <- data.frame(TTW)
names(TTW) <- c("word","freq")
pal <- brewer.pal(9,"RdBu")
wordcloud(TTW$word, TTW$freq, colors=pal, random.order=F, max.words=200)
```

Well, that is kinda cool.  Now, I want to do a bit more with it using more complicated word combinations.

## The Wonders of tidytext

The *tidytext* [section on n-grams](https://www.tidytextmining.com/ngrams.html) is great.  I will start with a tweet identifier -- something I should have deployed long ago -- before parsing these.

```{r}
library(tidyr)
CT <- clean_tweets %>% mutate(tweetno= row_number())
DJT2G <- clean_tweets %>% unnest_tokens(bigram, text, token = "ngrams", n=2)

bigrams_separated <- DJT2G %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

my.df <- data.frame(table(bigrams_united))
my.df <- my.df[order(my.df$Freq, decreasing=TRUE),]
my.df <- my.df[c(1:500),]
```

With that, we have the data for the bigram cloud.

```{r, eval=FALSE, echo=FALSE}
library(wordcloud2)
wordcloud2(my.df, color="random-light", backgroundColor = "black")
```

After seeing a few competing renditions, I prefer `wordcloud2`.  One thing to be careful about is scaling.  In this case, the most frequent bigram is missing because the ratio makes it too large to fit.  With size smaller, it can be made to show.

```{r}
library(wordcloud2)
wordcloud2(my.df, color="random-light", backgroundColor = "black", size = 0.7)
```

I think that works quite nicely.  The use of jpg for shapes has not worked for me.

```{r}
wordcloud2(my.df, figPath = "tweeter.jpg", size = 0.5, color = "pink")
```

